
**块设备**：   
<img src="https://github.com/Yongli-Lisa/Linux-Notes1/blob/bed5216b4e280f6eebe4aa0282cc3dfde05aff51/Img/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E5%9D%97%E8%AE%BE%E5%A4%87.JPG" width="800px">   

        
**块设备遇到的文件系统**：   
块设备遇到的第一个文件系统：插入盘时，mknod 会创建在 /dev 路径下面，/dev 路径下面是 devtmpfs 文件系统。会为这个块设备文件，分配一个特殊的 inode。   
块设备遇到的第二个文件系统：接下来，调用 mount，将这个块设备文件挂载到一个文件夹下面。如果这个块设备原来被格式化为一种文件系统的格式，例如 ext4，那我们调用的就是 ext4 相应的 mount 操作。这个文件系统也是向这个块设备读写文件，需要基于的主流文件系统。
（mount主要做两件事情，1是找到设备并打开它，2是填充ext4 文件系统的 super_block）   
块设备遇到的第三个文件系统：bdev 伪文件系统，所有表示块设备的 inode 都保存在伪文件系统 bdev 中，这些对用户层不可见，主要为了方便块设备的管理。   
总结：    
设备文件 /dev/xxx 在 devtmpfs 文件系统中，找到 devtmpfs 文件系统中的 inode，里面有 dev_t。我们可以通过 dev_t，在伪文件系统 bdev 中找到对应的 inode，然后根据 struct bdev_inode 找到关联的 block_device。
在找到 block_device 之后，要调用 blkdev_get 打开这个设备。blkdev_get 会调用 __blkdev_get。   

**分区**:   
我们有一个磁盘 /dev/sda，我们既可以把它整个格式化成一个文件系统，也可以把它分成多个分区 /dev/sda1、 /dev/sda2，然后把每个分区格式化成不同的文件系统：   
<img src="https://github.com/Yongli-Lisa/Linux-Notes1/blob/bed5216b4e280f6eebe4aa0282cc3dfde05aff51/Img/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E5%9D%97%E5%88%86%E5%8C%BA%E7%BB%93%E6%9E%84.JPG" width="800px">   

**总结**：   
<img src="https://github.com/Yongli-Lisa/Linux-Notes1/blob/a77f8518a9aa09a95867f5c81c77b1f08cf8b857/Img/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E5%9D%97%E8%AE%BE%E5%A4%87%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png" width="800px">   

1. 所有的块设备被一个 map 结构管理从 dev_t 到 gendisk 的映射；
2. 所有的 block_device 表示的设备或者分区都在 bdev 文件系统的 inode 列表中；
3. mknod 创建出来的块设备文件在 devtemfs 文件系统里面，特殊 inode 里面有块设备号；
4. mount 一个块设备上的文件系统，调用这个文件系统的 mount 接口；
5. 通过按照 /dev/xxx 在文件系统 devtmpfs 文件系统上搜索到特殊 inode，得到块设备号；
6. 根据特殊 inode 里面的 dev_t 在 bdev 文件系统里面找到 inode；
7. 根据 bdev 文件系统上的 inode 找到对应的 block_device，根据 dev_t 在 map 中找到 gendisk，将两者关联起来；
8. 找到 block_device 后打开设备，调用和 block_device 关联的 gendisk 里面的 block_device_operations 打开设备；
9. 创建被 mount 的文件系统的 super_block。


**块设备队列结构**:   
<img src="https://github.com/Yongli-Lisa/Linux-Notes1/blob/d34a3c912269c20d0dace22c273e6759077fa4f5/Img/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E5%9D%97%E8%AE%BE%E5%A4%87%E9%98%9F%E5%88%97%E7%BB%93%E6%9E%84.JPG" width="200px">   

**电梯算法**:   
struct elevator_type elevator_noop：Noop 调度算法是最简单的 IO 调度算法，它将 IO 请求放入到一个 FIFO 队列中，然后逐个执行这些 IO 请求。   
struct elevator_type iosched_deadline：Deadline 算法要保证每个 IO 请求在一定的时间内一定要被服务到，以此来避免某个请求饥饿。为了完成这个目标，算法中引入了两类队列，一类队列用来对请求按起始扇区序号进行排序，通过红黑树来组织，我们称为 sort_list，按照此队列传输性能会比较高；另一类队列对请求按它们的生成时间进行排序，由链表来组织，称为 fifo_list，并且每一个请求都有一个期限值。   
struct elevator_type iosched_cfq：CFQ 完全公平调度算法。所有的请求会在多个队列中排序。同一个进程的请求，总是在同一队列中处理。时间片会分配到每个队列，通过轮询算法，我们保证了 I/O 带宽，以公平的方式，在不同队列之间进行共享。（默认算法）    


我们用两块硬盘组成 RAID，两个 RAID 盘组成 LVM，然后我们就可以在 LVM 上创建一个块设备给用户用，我们称接近用户的块设备为高层次的块设备，接近底层的块设备为低层次（lower）的块设备。   
这样，generic_make_request 把 I/O 请求发送给高层次的块设备的时候，会调用高层块设备的 make_request_fn，高层块设备又要调用 generic_make_request，将请求发送给低层次的块设备。虽然块设备的层次不会太多，但是对于代码 generic_make_request 来讲，这可是递归的调用，一不小心，就会递归过深，无法正常退出，而且内核栈的大小又非常有限，所以要比较小心。    


**块设备IO送达外部设备流程**:   
<img src="https://github.com/Yongli-Lisa/Linux-Notes1/blob/2e10b9bb2b6a56a126aae83c9821d724bb2f1035/Img/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E5%9D%97%E8%AE%BE%E5%A4%87IO%E9%80%81%E8%BE%BE%E5%A4%96%E9%83%A8%E8%AE%BE%E5%A4%87%E6%B5%81%E7%A8%8B.JPG" width="1800px">   


/sys/block/xvda/queue/scheduler 磁盘的调度算法，   
临时修改：echo noop > /sys/block/xvda/queue/scheduler，永久修改就需要修改内核参数，然后重启。   
iostat -d  -x 中的avgqu-sz是平均I/O队列长度。   
